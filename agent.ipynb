{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import glob\n",
    "import logging\n",
    "import getpass\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "# Configure logging\n",
    "logging.basicConfig(filename=\"code_agent.log\", level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANTHROPIC_API_KEY = getpass.getpass('ANTHROPIC_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-large-latest\"\n",
    "\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\Spectra\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Setup \n",
    "model_name = \"claude-3-sonnet-20240229\"\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "mixtral = HuggingFaceEndpoint(repo_id=repo_id, temperature=0.3)\n",
    "\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-large-latest\",\n",
    "    temperature=0.3,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"claude-3-sonnet-20240229\"\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_011DRvk3DaGCqN9bH2yJJ74h', content=[TextBlock(text=\"My name is Claude. It's nice to meet you!\", type='text')], model='claude-3-sonnet-20240229', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(input_tokens=11, output_tokens=15))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.messages.create(\n",
    "    model=model_name,\n",
    "    messages=[{\"role\": \"user\", \"content\":\"Tell me your name\"}],\n",
    "    max_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions\n",
    "def clone_github_repo(url: str, folder: str):\n",
    "    \"\"\"\n",
    "    Clone a GitHub repository to a specified folder.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Cloning GitHub repository from {url} to {folder}...\")\n",
    "        subprocess.run([\"git\", \"clone\", url, folder], check=True)\n",
    "        logging.info(\"Repository cloned successfully.\")\n",
    "        return {\"success\": True, \"folder\": f\"repo successfully cloned into {folder}\"}\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(f\"Failed to clone repository: {e}\")\n",
    "        return {\"success\": False, \"folder\": f\"repo unsuccessfully cloned into {folder}\"}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        return {\"success\": False, \"folder\": f\"repo unsuccessfully cloned into {folder}\"}\n",
    "def save_folder_structure(folder: str, output_file: str):\n",
    "    \"\"\"\n",
    "    Save the folder structure to a markdown file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Saving folder structure of {folder} to {output_file}...\")\n",
    "        with open(output_file, \"w\") as f:\n",
    "            for root, dirs, files in os.walk(folder):\n",
    "                level = root.replace(folder, \"\").count(os.sep)\n",
    "                indent = \" \" * 4 * level\n",
    "                f.write(f\"{indent}{os.path.basename(root)}/\\n\")\n",
    "                sub_indent = \" \" * 4 * (level + 1)\n",
    "                for file in files:\n",
    "                    f.write(f\"{sub_indent}{file}\\n\")\n",
    "        logging.info(\"Folder structure saved successfully.\")\n",
    "        return {\"success\": True, \"output_file\": f\"Folder structure successfully written into {output_file}\"}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while saving folder structure: {e}\")\n",
    "        return {\"success\": False, \"output_file\": f\"Folder structure unsuccessfully written into {output_file}\"}\n",
    "def list_files(folder: str, patterns: list):\n",
    "    \"\"\"\n",
    "    List all files in the specified folder that match the given patterns.\n",
    "    \"\"\"\n",
    "    matching_files = []\n",
    "    for pattern in patterns:\n",
    "        matching_files.extend(glob.glob(os.path.join(folder, pattern), recursive=True))\n",
    "    return matching_files\n",
    "\n",
    "def summarize_files(folder: str, output_file: str):\n",
    "    \"\"\"\n",
    "    Summarize code and markdown files in the folder and append to the output file.\n",
    "    \"\"\"\n",
    "    file_patterns = [\"**/*.py\", \"**/*.js\", \"**/*.java\", \"**/*.cpp\", \"**/*.md\"]\n",
    "    try:\n",
    "        # Step 1: List all files that match the patterns\n",
    "        files_to_summarize = list_files(folder, file_patterns)\n",
    "\n",
    "        logging.info(f\"Summarizing files in {folder} and appending to {output_file}...\")\n",
    "\n",
    "        with open(output_file, \"a\") as f:\n",
    "            f.write(\"\\n## File Summaries\\n\\n\")\n",
    "\n",
    "            # Step 2: Read and summarize each file\n",
    "            for file_path in files_to_summarize:\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as file:\n",
    "                        content = file.read()\n",
    "                        if not content.strip():\n",
    "                            logging.warning(f\"File {file_path} is empty. Skipping.\")\n",
    "                            f.write(f\"### {file_path}\\nWarning: File is empty. No summary generated.\\n\\n\")\n",
    "                            continue\n",
    "\n",
    "                        # Summarize the content\n",
    "                        summary = summarize_content(content)\n",
    "                        if summary.get(\"success\"):\n",
    "                            f.write(f\"### {file_path}\\n{summary['summary']}\\n\\n\")\n",
    "                        else:\n",
    "                            logging.error(f\"Summary generation failed for {file_path}.\")\n",
    "                            f.write(f\"### {file_path}\\nWarning: Summary generation failed.\\n\\n\")\n",
    "                \n",
    "                except Exception as file_error:\n",
    "                    logging.error(f\"An error occurred while reading file {file_path}: {file_error}\")\n",
    "                    f.write(f\"### {file_path}\\nWarning: Could not read the file due to an error.\\n\\n\")\n",
    "        \n",
    "        logging.info(\"File summaries saved successfully.\")\n",
    "        return {\"success\": True, \"output_file\": f\"Summary successfully written into {output_file}\"}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while summarizing files: {e}\")\n",
    "        return {\"success\": False, \"output_file\": f\"Summary could not be written into {output_file}\"}\n",
    "\n",
    "def summarize_content(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Use an LLM to summarize the content of a file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        system = \"\"\"\n",
    "        You are an advanced code assistant specialized in summarizing technical content, including source code and documentation. Your task is:\n",
    "            - Given the content of a code file or documentation, generate a concise yet informative summary that highlights the primary purpose and key components.\n",
    "            - Ensure that the summary is well-written and can be understood by someone who needs an overview without diving into the details of the code.\n",
    "            - The summary should be between 2 to 5 sentences, focusing on the main purpose and key functions provided by the code or document.\n",
    "            - Return a success or failure message depending on whether a summary could be generated, and include error handling for unexpected content formats.\n",
    "\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            (\"system\", system),\n",
    "            (\"human\", f\"Please summarize the following content:\\n\\n{content}\"),\n",
    "        ]\n",
    "        logging.info(\"Requesting LLM to summarize content...\")\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        return {\"success\": True, \"summary\": f\"Summary successfully generated {ai_msg.content}\"}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while summarizing content: {e}\")\n",
    "        return {\"success\": False, \"summary\": f\"Summary not generated\"}\n",
    "\n",
    "def generate_documentation(input_file: str, output_file: str):\n",
    "    \"\"\"\n",
    "    Generate comprehensive documentation based on the preliminary analysis.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Generating documentation based on {input_file}...\")\n",
    "        with open(input_file, \"r\") as f:\n",
    "            content = f.read()\n",
    "        system = \"\"\"\n",
    "        You are a highly knowledgeable technical assistant that generates comprehensive documentation for software codebases. Your task is:\n",
    "            - Given a preliminary analysis of the codebase, generate detailed documentation that is suitable for a README file.\n",
    "            - The documentation should cover an overview of the project, its purpose, features, dependencies, installation instructions, and usage.\n",
    "            - Focus on making the documentation informative, easy to follow, and clear, ensuring it provides sufficient information for a new developer or user to understand the project.\n",
    "            - Do not include any code—only include narrative text that explains the project.\n",
    "            - The documentation should be well-structured, using headers and subheaders where appropriate, and save it to the specified output file.\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            (\"system\", system),\n",
    "            (\"human\", f\"Based on the following preliminary analysis, generate comprehensive documentation for the entire codebase:\\n\\n{content}\"),\n",
    "        ]\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(ai_msg.content)\n",
    "        logging.info(\"Documentation generated successfully.\")\n",
    "        return {\"success\": True, \"output\": f\"Documentation written in {output_file}\"}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while generating documentation: {e}\")\n",
    "        return {\"success\": False, \"output\": f\"Documentation not written in {output_file}\"}\n",
    "def generate_instructions(input_file: str, output_file: str):\n",
    "    \"\"\"\n",
    "    Convert documentation into clear instructions for recreating the codebase.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Generating instructions from {input_file}...\")\n",
    "        with open(input_file, \"r\") as f:\n",
    "            content = f.read()\n",
    "        system =\"\"\" \n",
    "        You are an expert assistant in converting software documentation into actionable instructions. Your task is:\n",
    "            - Based on the provided documentation, generate a set of clear, step-by-step instructions for recreating the codebase.\n",
    "            - The instructions should be written clearly enough for a software engineer to recreate the entire codebase from scratch.\n",
    "            - Do not include any actual code—focus entirely on the steps required, such as \"Create a file named X\", \"Include Y dependencies\", \"Write function Z to do A\", etc.\n",
    "            - Ensure the instructions are comprehensive, cover all steps in detail, and are structured in a logical sequence.\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            (\"system\", system),\n",
    "            (\"human\", f\"Based on the following documentation, provide clear instructions to recreate the codebase:\\n\\n{content}\"),\n",
    "        ]\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(ai_msg.content)\n",
    "        logging.info(\"Instructions generated successfully.\")\n",
    "        return {\"success\": True, \"output\": f\"Instructions written in {output_file}\"}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while generating instructions: {e}\")\n",
    "        return {\"success\": False, \"output\": f\"Instructions not written in {output_file}\"}\n",
    "\n",
    "\n",
    "def recreate_codebase(instructions_file: str, output_folder: str):\n",
    "    \"\"\"\n",
    "    Recreate the codebase based on the instructions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Recreating codebase based on {instructions_file}...\")\n",
    "        \n",
    "        # Read the instructions file\n",
    "        with open(instructions_file, \"r\") as f:\n",
    "            instructions = f.read()\n",
    "        system = \"\"\" \n",
    "        You are an expert software developer responsible for recreating software codebases based on given instructions. Your task is:\n",
    "            - Based on the provided instructions, generate the full codebase.\n",
    "            - For each file, start by indicating the file name using the format 'file: <filename>', followed by the file content.\n",
    "            - Only generate the exact content that belongs in each file—do not include additional commentary, instructions, or explanatory notes.\n",
    "            - Ensure that the output is structured clearly so that it can be directly parsed and saved into the respective files.\n",
    "            - Return the generated code in a format that can be used to create all necessary files for the project.\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        # Send instructions to LLM to generate the codebase\n",
    "        messages = [\n",
    "                    (\"system\", system),\n",
    "                    (\"human\", f\"Please recreate the codebase based on these instructions:\\n\\n{instructions}\"),\n",
    "                ]\n",
    "\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        generated_code = ai_msg.content\n",
    "        print(generated_code)\n",
    "        # Check if any code was generated\n",
    "        if not generated_code.strip():\n",
    "            logging.error(\"No code was generated from the instructions.\")\n",
    "            return {\"success\": False, \"output\": \"No code generated.\"}\n",
    "        \n",
    "        logging.info(\"Generated code successfully received from LLM.\")\n",
    "\n",
    "        # Parse the generated code and create files\n",
    "        current_file = None\n",
    "        current_content = []\n",
    "\n",
    "        for line in generated_code.split(\"\\n\"):\n",
    "            # Start of a new file\n",
    "            if line.startswith(\"file:\") and \":\" in line:\n",
    "                # Write the previous file's content (if any)\n",
    "                if current_file:\n",
    "                    file_path = os.path.join(output_folder, current_file)\n",
    "                    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "                    with open(file_path, \"w\") as f:\n",
    "                        f.write(\"\\n\".join(current_content))\n",
    "                    logging.info(f\"Created file: {file_path}\")\n",
    "                \n",
    "                # Prepare to capture the new file\n",
    "                current_file = line.split(\":\", 1)[1].strip()\n",
    "                current_content = []\n",
    "\n",
    "            # Continue capturing the content of the current file\n",
    "            elif current_file:\n",
    "                current_content.append(line)\n",
    "\n",
    "        # Write the final file's content (if any)\n",
    "        if current_file:\n",
    "            file_path = os.path.join(output_folder, current_file)\n",
    "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "            with open(file_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(current_content))\n",
    "            logging.info(f\"Created file: {file_path}\")\n",
    "\n",
    "        logging.info(\"Codebase recreated successfully.\")\n",
    "        return {\"success\": True, \"output\": f\"Code recreated in {output_folder}\"}\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while recreating the codebase: {e}\")\n",
    "        return {\"success\": False, \"output\": f\"Code not recreated in {output_folder}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"clone_github_repo\",\n",
    "        \"description\": \"Clones a GitHub repository to a specified folder.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"url\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The URL of the GitHub repository to clone.\"\n",
    "                },\n",
    "                \"folder\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The folder where the repository will be cloned.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"url\", \"folder\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"save_folder_structure\",\n",
    "        \"description\": \"Saves the folder structure of a specified folder to a markdown file.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"folder\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The folder to be analyzed for its structure.\"\n",
    "                },\n",
    "                \"output_file\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The output markdown file to save the folder structure.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"folder\", \"output_file\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"summarize_files\",\n",
    "        \"description\": \"Summarizes code and markdown files in a folder and appends the summary to an output file.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"folder\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The folder containing the files to summarize.\"\n",
    "                },\n",
    "                \"output_file\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The output file where summaries will be appended.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"folder\", \"output_file\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"generate_documentation\",\n",
    "        \"description\": \"Generates comprehensive documentation based on the preliminary analysis of a given input file.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"input_file\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The input file containing the preliminary analysis.\"\n",
    "                },\n",
    "                \"output_file\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The output file where the generated documentation will be saved.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"input_file\", \"output_file\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"generate_instructions\",\n",
    "        \"description\": \"Generates clear instructions for recreating the codebase based on the provided documentation.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"input_file\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The input file containing the codebase documentation.\"\n",
    "                },\n",
    "                \"output_file\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The output file where the generated instructions will be saved.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"input_file\", \"output_file\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"recreate_codebase\",\n",
    "        \"description\": \"Recreates the codebase based on the instructions from the input file.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"instructions_file\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The input file containing instructions to recreate the codebase.\"\n",
    "                },\n",
    "                \"output_folder\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The folder where the recreated codebase will be saved.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"instructions_file\", \"output_folder\"]\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle tool call function\n",
    "\n",
    "def process_tool_call(tool_block):\n",
    "    tool_name = tool_block.name\n",
    "    arguments = tool_block.input if tool_block.input else {}\n",
    "    if tool_name == \"clone_github_repo\":\n",
    "        return clone_github_repo(arguments[\"url\"], arguments[\"folder\"])\n",
    "    elif tool_name == \"save_folder_structure\":\n",
    "        return save_folder_structure(arguments[\"folder\"], arguments[\"output_file\"])\n",
    "    elif tool_name == \"summarize_files\":\n",
    "        return summarize_files(arguments[\"folder\"], arguments[\"output_file\"])\n",
    "    elif tool_name == \"generate_documentation\":\n",
    "        return generate_documentation(arguments[\"input_file\"], arguments[\"output_file\"])\n",
    "    elif tool_name == \"generate_instructions\":\n",
    "        return generate_instructions(arguments[\"input_file\"], arguments[\"output_file\"])\n",
    "    elif tool_name == \"recreate_codebase\":\n",
    "        return recreate_codebase(arguments[\"instructions_file\"], arguments[\"output_folder\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Tool '{tool_name}' is not recognized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_llm_invocation(github_url: str):\n",
    "    # State dictionary to track which steps have been completed\n",
    "    state = {\n",
    "        \"repo_cloned\": False,\n",
    "        \"structure_saved\": False,\n",
    "        \"files_summarized\": False,\n",
    "        \"documentation_generated\": False,\n",
    "        \"instructions_generated\": False,\n",
    "        \"codebase_recreated\": False\n",
    "    }\n",
    "\n",
    "    # System prompt describing the overall context and goal\n",
    "    system_prompt = f\"\"\"\n",
    "    You are a helpful assistant that handles software development workflows. You can use tools to interact with GitHub repositories, summarize code, generate documentation, and recreate codebases. Your task is to guide the process by invoking the necessary tools in sequence to complete the workflow based on the user's request. You should:\n",
    "    You are provided with the following GitHub repository URL: {github_url}.\n",
    "\n",
    "    Your goal is to execute the following steps in sequence using the available tools:\n",
    "    1. Clone the GitHub repository into the specified folder.\n",
    "    2. Save the folder structure of the cloned repository into a markdown file.\n",
    "    3. Summarize the content of the relevant code and markdown files and append these summaries to an output file.\n",
    "    4. Generate comprehensive documentation for the codebase based on the summaries.\n",
    "    5. Convert the generated documentation into clear instructions for recreating the codebase.\n",
    "    6. Recreate the codebase into a separate specified folder using the generated instructions.\n",
    "\n",
    "    You are allowed to use the following folder names and file paths for each step:\n",
    "\n",
    "    - **Cloning the Repository**:\n",
    "      - GitHub URL: `{github_url}`\n",
    "      - Target folder: `cloned_repo`\n",
    "\n",
    "    - **Saving Folder Structure**:\n",
    "      - Folder to analyze: `cloned_repo`\n",
    "      - Output markdown file: `folder_structure.md`\n",
    "\n",
    "    - **Summarizing Files**:\n",
    "      - Folder to summarize: `cloned_repo`\n",
    "      - Output file for summaries: `file_summaries.md`\n",
    "\n",
    "    - **Generating Documentation**:\n",
    "      - Input file for analysis: `file_summaries.md`\n",
    "      - Output documentation file: `documentation.md`\n",
    "\n",
    "    - **Generating Instructions for Recreating Codebase**:\n",
    "      - Input documentation file: `documentation.md`\n",
    "      - Output instructions file: `instructions.md`\n",
    "\n",
    "    - **Recreating the Codebase**:\n",
    "      - Input instructions file: `instructions.md`\n",
    "      - Output folder for recreated codebase: `recreated_codebase`\n",
    "\n",
    "    At each step, make sure to use the available tools logically and complete each part of the workflow before moving on to the next. Continue until the entire workflow is completed successfully.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Recreate the code for me: The GitHub URL is {github_url}\n",
    "    \"\"\"\n",
    "\n",
    "    # Initial messages list without system prompt\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    # Loop until all steps are completed\n",
    "    while not all(state.values()):\n",
    "        # Invoke the LLM to determine the flow\n",
    "        response = client.messages.create(\n",
    "            model=model_name,\n",
    "            max_tokens=4096,\n",
    "            tools=tools,  # The list of tool definitions provided earlier\n",
    "            system=system_prompt,  # Pass system prompt separately\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        # Process the response and tool invocations until the entire workflow is complete\n",
    "        if response.stop_reason == \"tool_use\":\n",
    "            tool_use = next((block for block in response.content if block.type == \"tool_use\"), None)\n",
    "            if tool_use:\n",
    "                tool_name = tool_use.name\n",
    "                tool_input = tool_use.input\n",
    "\n",
    "                # Invoke the tool and get the output\n",
    "                tool_output = process_tool_call(tool_use)\n",
    "                print(f\"Tool Output for '{tool_name}': {tool_output}\")\n",
    "\n",
    "                # Update state based on the tool used\n",
    "                if tool_name == \"clone_github_repo\":\n",
    "                    state[\"repo_cloned\"] = True\n",
    "                elif tool_name == \"save_folder_structure\":\n",
    "                    state[\"structure_saved\"] = True\n",
    "                elif tool_name == \"summarize_files\":\n",
    "                    state[\"files_summarized\"] = True\n",
    "                elif tool_name == \"generate_documentation\":\n",
    "                    state[\"documentation_generated\"] = True\n",
    "                elif tool_name == \"generate_instructions\":\n",
    "                    state[\"instructions_generated\"] = True\n",
    "                elif tool_name == \"recreate_codebase\":\n",
    "                    state[\"codebase_recreated\"] = True\n",
    "\n",
    "                # Append the tool's result to messages to provide context to the LLM\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Tool '{tool_name}' was used successfully. Here is the output: {json.dumps(tool_output)}. Please proceed to the next step.\"\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                print(\"No valid tool use was found in the response content.\")\n",
    "        else:\n",
    "            # Break the loop if no more tools are needed\n",
    "            break\n",
    "\n",
    "    # Final response after tool usage is complete\n",
    "    print(\"\\n===== Final Output from LLM =====\")\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Output for 'clone_github_repo': {'success': True, 'folder': 'repo successfully cloned into cloned_repo'}\n",
      "Tool Output for 'save_folder_structure': {'success': True, 'output_file': 'Folder structure successfully written into folder_structure.md'}\n",
      "Tool Output for 'summarize_files': {'success': True, 'output_file': 'Summary successfully written into file_summaries.md'}\n",
      "Tool Output for 'generate_documentation': {'success': True, 'output': 'Documentation written in documentation.md'}\n",
      "Tool Output for 'generate_instructions': {'success': True, 'output': 'Instructions written in instructions.md'}\n",
      "```\n",
      "file: app.py\n",
      "import streamlit as st\n",
      "import pandas as pd\n",
      "import joblib\n",
      "\n",
      "model = joblib.load('iris_model.pkl')\n",
      "\n",
      "st.title('Iris Flowers Classification App')\n",
      "\n",
      "# Input features using sliders\n",
      "sepal_length = st.slider('Sepal Length', 0.0, 10.0, 5.0)\n",
      "sepal_width = st.slider('Sepal Width', 0.0, 10.0, 5.0)\n",
      "petal_length = st.slider('Petal Length', 0.0, 10.0, 5.0)\n",
      "petal_width = st.slider('Petal Width', 0.0, 10.0, 5.0)\n",
      "\n",
      "# Create a DataFrame with the input features\n",
      "input_data = pd.DataFrame({\n",
      "    'sepal_length': [sepal_length],\n",
      "    'sepal_width': [sepal_width],\n",
      "    'petal_length': [petal_length],\n",
      "    'petal_width': [petal_width]\n",
      "})\n",
      "\n",
      "if st.button('Predict'):\n",
      "    prediction = model.predict(input_data)\n",
      "    prediction_proba = model.predict_proba(input_data)\n",
      "\n",
      "    st.write('Predicted Iris Species:', iris.target_names[prediction][0])\n",
      "    st.write('Prediction Probabilities:', prediction_proba)\n",
      "\n",
      "file: model.py\n",
      "import pandas as pd\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Load the Iris dataset\n",
      "iris = load_iris()\n",
      "X = iris.data\n",
      "y = iris.target\n",
      "\n",
      "# Split the dataset into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# Train the SVC model\n",
      "model = SVC(probability=True)\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "import joblib\n",
      "joblib.dump(model, 'iris_model.pkl')\n",
      "\n",
      "file: requirements.txt\n",
      "streamlit\n",
      "pandas\n",
      "scikit-learn\n",
      "```\n",
      "Tool Output for 'recreate_codebase': {'success': True, 'output': 'Code recreated in recreated_codebase'}\n",
      "\n",
      "===== Final Output from LLM =====\n",
      "[ToolUseBlock(id='toolu_01Rrs3F15X56QACD9GMUJncx', input={'instructions_file': 'instructions.md', 'output_folder': 'recreated_codebase'}, name='recreate_codebase', type='tool_use')]\n"
     ]
    }
   ],
   "source": [
    "GITHUB_REPO_URL = \"https://github.com/KimaniKibuthu/iris-flowers-app.git\"\n",
    "single_llm_invocation(GITHUB_REPO_URL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
